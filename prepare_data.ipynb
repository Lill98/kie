{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"20231123_dataset2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input_yolo_format(path_json, path_json_out):\n",
    "    \"\"\"Convert to final result\n",
    "\n",
    "    Args:\n",
    "        ocr_result (dataframe): output of model XGBoost\n",
    "\n",
    "    Returns:\n",
    "        json: final result\n",
    "    \"\"\"\n",
    "    # print(path_image)\n",
    "    try:    \n",
    "        with open(path_json) as f:\n",
    "            ocr_result = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    if len(ocr_result)==0:\n",
    "        return \"\"\n",
    "    name_image = path_json.split(\"/\")[-1].replace(\"out.json\",\"jpg\")\n",
    "    annotation_1_file = {\"image_name\": name_image,\"ocr\":None}\n",
    "    final_ocr_result = []\n",
    "    for idx, box in enumerate(ocr_result):\n",
    "        final_ocr_result.append({\"box\":[box[\"points\"][0][0], \n",
    "                                  box[\"points\"][0][1],\n",
    "                                  box[\"points\"][2][0],\n",
    "                                  box[\"points\"][2][1]],\n",
    "                           \"text\":box[\"transcription\"]})\n",
    "        \n",
    "    annotation_1_file[\"ocr\"] =  final_ocr_result\n",
    "         \n",
    "    with open(path_json_out, \"w\", encoding=\"utf-8\") as fff:\n",
    "        json.dump(annotation_1_file, fff, ensure_ascii=False)\n",
    "    # return json.dumps(annotation_1_file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(root):\n",
    "    path_folder = os.path.join(root, folder)\n",
    "    path_annotation = os.path.join(path_folder, \"annotation\")\n",
    "    path_out_annotation = os.path.join(path_folder, \"annotation_convert\")\n",
    "    os.makedirs(path_out_annotation, exist_ok = True)\n",
    "    for json_file in os.listdir(path_annotation):\n",
    "        path_json_file = os.path.join(path_annotation, json_file)\n",
    "        path_json_out =  os.path.join(path_out_annotation, json_file)\n",
    "        convert_input_yolo_format(path_json_file, path_json_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert result to yolo format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_out_ser = \"/mnt/28857F714F734EE8/projects/chatgpt/infordio-key_value_extraction/key-value-extractor/output/163_output/ser\"\n",
    "root_out_re = \"/mnt/28857F714F734EE8/projects/chatgpt/infordio-key_value_extraction/key-value-extractor/output/163_output/re\"\n",
    "root_yolo = \"/mnt/28857F714F734EE8/projects/chatgpt/infordio-key_value_extraction/key-value-extractor/output/163_output/yolo\"\n",
    "os.makedirs(root_yolo, exist_ok=True)\n",
    "classes_path = \"output/classes.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(classes_path, \"r\") as f:\n",
    "    content = f.read().splitlines()\n",
    "dict_classes = {class_:idx for idx,class_ in enumerate(content)}\n",
    "dict_classes_sigle = {class_:idx for class_,idx in dict_classes.items() if \".\" not in class_ and \"k19\" not in class_}\n",
    "dict_classes_multiple = {class_:idx for class_,idx in dict_classes.items() if \".\"  in class_}\n",
    "dict_idx_classes_sigle = {idx:class_ for class_,idx in dict_classes.items() if \".\" not in class_ and \"k19\" not in class_}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['other', 'k1', 'v1', 'k2', 'v2', 'k3', 'v3', 'k4', 'v4', 'k5', 'v5', 'k6', 'v6', 'k7', 'v7', 'k8', 'v8', 'k9', 'v9', 'k10', 'v10', 'k11', 'v11', 'k12', 'v12', 'k13', 'v13', 'k14', 'v14', 'k15', 'v15', 'k16', 'v16', 'k17', 'v17', 'k18', 'v18', 'header', 'k20', 'v20', 'k21', 'v21', 'k22', 'v22', 'k23', 'v23', 'k24', 'v24', 'k25', 'v25', 'k26', 'v26', 'k27', 'v27', 'k28', 'v28', 'k29', 'v29', 'k30', 'v30', 'k31', 'v31', 'k32', 'v32', 'k33', 'v33', 'k34', 'v34', 'k35', 'v35', 'k36', 'v36', 'k37', 'v37', 'k38', 'v38'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_classes_sigle.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_ser(path_json, path_image):\n",
    "    try:    \n",
    "        with open(path_json) as f:\n",
    "            ocr_result = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    final_dict = {}\n",
    "    # print(path_image)\n",
    "    image = cv2.imread(path_image)\n",
    "    h,w,c = image.shape\n",
    "    for value in ocr_result:\n",
    "        x_center = (value[\"bbox\"][0] + value[\"bbox\"][2])/(2*w)\n",
    "        y_center = (value[\"bbox\"][1] + value[\"bbox\"][3])/(2*h)\n",
    "        w_box = (value[\"bbox\"][2] - value[\"bbox\"][0])/(w)\n",
    "        h_box = (value[\"bbox\"][3] - value[\"bbox\"][1])/(h)\n",
    "        if value[\"pred\"] == \"TITLE\":\n",
    "            label = dict_classes_sigle[\"header\"]\n",
    "        else:\n",
    "            label = dict_classes_sigle[\"other\"]\n",
    "            \n",
    "        final_dict[value[\"id\"]] = f\"{label} {x_center} {y_center} {w_box} {h_box}\"\n",
    "        \n",
    "    return final_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_value_content(content, new_class_id):\n",
    "    content = content.split()\n",
    "    content = \" \".join([str(new_class_id)] + content[1:])\n",
    "    return content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_re(path_json, result_ser):\n",
    "    try:    \n",
    "        with open(path_json) as f:\n",
    "            ocr_result = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    final_dict = {}\n",
    "    # print(path_image)\n",
    "    start_idx = 1\n",
    "    for idx, pair_value in enumerate(ocr_result):\n",
    "        key_id = pair_value[0][\"id\"]\n",
    "        value_id = pair_value[1][\"id\"]\n",
    "        # print(key_id)\n",
    "        # print(result_ser)\n",
    "        # print(result_ser[key_id])\n",
    "        \n",
    "        # print(int(result_ser[key_id].split()[0]))\n",
    "        # print(int(result_ser[key_id].split()))\n",
    "        if int(result_ser[key_id].split()[0]) != 0:\n",
    "            label_class = dict_idx_classes_sigle[int(result_ser[key_id].split()[0])].replace(\"k\",\"v\")\n",
    "            idx_label = dict_classes_sigle[label_class]\n",
    "            result_ser[value_id] = change_value_content(result_ser[value_id], idx_label)\n",
    "        else:\n",
    "            # print(\"asaaa\")\n",
    "            new_index_key = f\"k{start_idx}\"\n",
    "            while not new_index_key in dict_classes_sigle:\n",
    "                start_idx += 1\n",
    "                new_index_key = f\"k{start_idx}\"\n",
    "            \n",
    "            # print(new_index_key)\n",
    "            \n",
    "            result_ser[key_id] = change_value_content(result_ser[key_id], dict_classes_sigle[new_index_key])\n",
    "            result_ser[value_id] = change_value_content(result_ser[value_id], dict_classes_sigle[new_index_key.replace(\"k\",\"v\")])\n",
    "            start_idx += 1\n",
    "            \n",
    "    return result_ser\n",
    "            \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_result = {}\n",
    "for file in os.listdir(root_out_ser):\n",
    "    if \"json\" not in file:\n",
    "        continue\n",
    "    path_json = os.path.join(root_out_ser, file)\n",
    "    path_image = path_json.replace(\"json\",\"jpg\")\n",
    "    dict_ser = mapping_ser(path_json, path_image)\n",
    "    ser_result[file] = dict_ser\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 326/326 [00:00<00:00, 6660.09it/s]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for file in tqdm.tqdm(os.listdir(root_out_re)):\n",
    "    if \"json\" not in file:\n",
    "        continue\n",
    "    # if i >0:\n",
    "    #     break\n",
    "    # if \"07-001_2520___original__2.外注費_代理店_SPITII_2207-0.out\" not in file:\n",
    "    #     continue\n",
    "    # print(file)\n",
    "    \n",
    "    path_json = os.path.join(root_out_re, file)\n",
    "    # print(path_json)\n",
    "    # print(ser_result[file])\n",
    "    result = mapping_re(path_json, ser_result[file])\n",
    "    path_out_yolo = os.path.join(root_yolo,file.replace(\"json\",\"txt\"))\n",
    "    content = \"\\n\".join(list(result.values()))\n",
    "    with open(path_out_yolo, \"w\") as f:\n",
    "        f.write(content)\n",
    "    # ser_result[file] = mapping_re(path_json, ser_result[file])\n",
    "    # print(result)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert data format's customer  to inference format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import shutil\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_txt = \"/home/infordio-ai/quan/code/information_extraction/PaddleOCR/train_data/dataset2/no2/163_image/163_images_no2.txt\"\n",
    "root_image = \"/home/infordio-ai/quan/code/information_extraction/PaddleOCR/train_data/dataset2/no2/imgs\"\n",
    "root_bbox = \"/home/infordio-ai/quan/code/information_extraction/PaddleOCR/train_data/dataset2/no2/bbox\"\n",
    "\n",
    "root_out_annotations_folder = \"/home/infordio-ai/quan/code/information_extraction/PaddleOCR/train_data/dataset2/no2/163_image/annotations\"\n",
    "root_out_image_folder = \"/home/infordio-ai/quan/code/information_extraction/PaddleOCR/train_data/dataset2/no2/163_image/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bbox2inf(path_init_json, path_json_out):\n",
    "    name_image = path_init_json.split(\"/\")[-1].replace(\"out.json\",\"jpg\")\n",
    "    final_json = {\"image_name\":name_image, \"ocr\":[]}\n",
    "    try:    \n",
    "        with open(path_init_json) as f:\n",
    "                ocr_result = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    annotation_1_file = []\n",
    "    if len(ocr_result)==0:\n",
    "        return \"\"\n",
    "    for idx, box in enumerate(ocr_result):\n",
    "        points = [[box[\"x\"], box[\"y\"]], \n",
    "                  [box[\"x\"]+box[\"w\"], box[\"y\"]],\n",
    "                  [box[\"x\"]+box[\"w\"], box[\"y\"]+box[\"h\"]],\n",
    "                  [box[\"x\"], box[\"y\"]+box[\"h\"]]]\n",
    "\n",
    "        text = box[\"text\"]\n",
    "        if type(text) != str: continue\n",
    "        \n",
    "        # annotation_1_file.append({\"transcription\": text, \"label\": \"other\", \"points\": points, \"id\": idx, \"linking\": []})\n",
    "        final_json[\"ocr\"].append({\"box\":[points[0][0], points[0][1], points[2][0], points[2][1]], \"text\": text})\n",
    "            \n",
    "    with open(path_json_out, \"w\", encoding=\"utf-8\") as fff:\n",
    "        json.dump(final_json, fff, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_txt, \"r\") as f:\n",
    "    contents = f.read().splitlines()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in contents:\n",
    "    path_in_image = os.path.join(root_image, image)\n",
    "    path_out_image = os.path.join(root_out_image_folder, image)\n",
    "    shutil.copy(path_in_image, path_out_image)\n",
    "    path_init_json = os.path.join(root_bbox, image.replace(\"jpg\",\"out.json\"))\n",
    "    # print(\"path_init_json\", path_init_json)\n",
    "    path_out_json = os.path.join(root_out_annotations_folder, image.replace(\"jpg\",\"json\"))\n",
    "        \n",
    "    convert_bbox2inf(path_init_json, path_out_json)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tuan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
