Global:
  use_gpu: False
  use_XGBoost: False
  epoch_num: &epoch_num 130
  log_smooth_window: 10
  print_batch_step: 10
  save_model_dir: ./output/re_vi_layoutxlm_key_value_20231030_all_data #change here
  save_epoch_step: 2000
  # evaluation is run every 10 iterations after the 0th iteration
  eval_batch_step: [ 0, 19 ]
  cal_metric_during_train: False
  save_inference_dir:
  use_visualdl: False
  seed: 2022
  image_folder: /home/infordio-ai/quan/code/information_extraction/PaddleOCR/train_data/20231026_relabel/final_qa_same_20230927/val/image
  ocr_file: /home/infordio-ai/quan/code/information_extraction/PaddleOCR/train_data/20231026_relabel/final_qa_same_20230927/val/val.json
  save_res_path: ./output/re/re_vi_layoutxlm_xfund_key_value_20231018_all_data/with_gt #change here
  kie_rec_model_dir: 
  kie_det_model_dir:

Architecture:
  model_type: kie
  algorithm: &algorithm "LayoutXLM"
  Transform:
  Backbone:
    name: LayoutXLMForRe
    pretrained: True
    mode: vi
    checkpoints:

    
PostProcess:
  name: VQAReTokenLayoutLMPostProcess


Eval:
  dataset:
    name: SimpleDataSet
    transforms:
      - DecodeImage: # load image
          img_mode: RGB
          channel_first: False
      - VQATokenLabelEncode: # Class handling label
          contains_re: True
          algorithm: *algorithm
          class_path: configs/class_list_qa.txt
          use_textline_bbox_info: True
          order_method: "tb-yx"
      - VQATokenPad:
          max_seq_len: 512
          return_attention_mask: True
      - VQAReTokenRelation:
      - VQAReTokenChunk:
          max_seq_len: 512
      - TensorizeEntitiesRelations:
      - Resize:
          size: [224,224]
      - NormalizeImage:
          scale: 1
          mean: [ 123.675, 116.28, 103.53 ]
          std: [ 58.395, 57.12, 57.375 ]
          order: 'hwc'
      - ToCHWImage:
      - KeepKeys:
          keep_keys: [ 'input_ids', 'bbox', 'attention_mask', 'token_type_ids', 'entities', 'relations'] # dataloader will return list in this order
